{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we compare **Autoencoders** and **Principal Component Analysis (PCA)** as dimensionality reduction techniques on the Fashion-MNIST dataset.\n",
        "\n",
        "The goal is to visualize, reconstruct, and cluster the data using both techniques and evaluate their quality using clustering metrics like:\n",
        "\n",
        "- Adjusted Rand Index (ARI)\n",
        "- Homogeneity Score\n",
        "- Silhouette Score\n",
        "\n",
        "We will also visualize the latent spaces using t-SNE.\n"
      ],
      "metadata": {
        "id": "0m4df9Wfyo2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import and Setup"
      ],
      "metadata": {
        "id": "en5qQq9iy0wI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import adjusted_rand_score, homogeneity_score, silhouette_score\n",
        "from tensorflow import keras\n"
      ],
      "metadata": {
        "id": "29AivwEuy8Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load and Preprocess MNIST-Fashion Dataset"
      ],
      "metadata": {
        "id": "JKnTziiLzE2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
        "X_train_full = X_train_full.astype(np.float32) / 255\n",
        "X_test = X_test.astype(np.float32) / 255\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
        "\n",
        "X_train = X_train.reshape(-1, 28 * 28)\n",
        "X_valid = X_valid.reshape(-1, 28 * 28)\n",
        "X_test = X_test.reshape(-1, 28 * 28)\n",
        "\n",
        "class_names = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "cluster_labels = [f\"Cluster {i}\" for i in range(10)]\n"
      ],
      "metadata": {
        "id": "dyfFEQEpzQfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Define Encoder and Decoder"
      ],
      "metadata": {
        "id": "zyyy8-hGzaX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X_train.shape[1]\n",
        "encoder_output_shape = 100\n",
        "\n",
        "encoder = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape),\n",
        "    keras.layers.Dense(512),\n",
        "    keras.layers.Dense(256),\n",
        "    keras.layers.Dense(128),\n",
        "    keras.layers.Dense(64),\n",
        "    keras.layers.Dense(encoder_output_shape)\n",
        "])\n",
        "\n",
        "decoder = keras.Sequential([\n",
        "    keras.layers.InputLayer((encoder_output_shape,)),\n",
        "    keras.layers.Dense(64),\n",
        "    keras.layers.Dense(128),\n",
        "    keras.layers.Dense(256),\n",
        "    keras.layers.Dense(512),\n",
        "    keras.layers.Dense(input_shape)\n",
        "])\n",
        "\n",
        "autoencoder = keras.Sequential([encoder, decoder])\n",
        "autoencoder.compile(loss=keras.losses.MeanSquaredError(),optimizer=keras.optimizers.Adam(learning_rate=0.001))\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
        "\n",
        "history = autoencoder.fit(X_train, X_train,epochs=50,validation_data=(X_valid, X_valid),\n",
        "                          callbacks=[early_stopping_cb],verbose=0)\n",
        "\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.title(\"Autoencoder Training Loss\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PJPwtyLmze7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Reconstruction Examples"
      ],
      "metadata": {
        "id": "svmeL0BNz2op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_reconstructions(model, images=X_valid, n_images=5):\n",
        "    reconstructions = np.clip(model.predict(images[:n_images]), 0, 1)\n",
        "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
        "\n",
        "    for image_index in range(n_images):\n",
        "        plt.subplot(2, n_images, 1 + image_index)\n",
        "        plt.imshow(images[image_index].reshape(28, 28), cmap=\"binary\")\n",
        "        plt.axis(\"off\")\n",
        "        if image_index == 0:\n",
        "            plt.title(\"Original\", fontsize=18, pad=10)\n",
        "\n",
        "    for image_index in range(n_images):\n",
        "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
        "        plt.imshow(reconstructions[image_index].reshape(28, 28), cmap=\"binary\")\n",
        "        plt.axis(\"off\")\n",
        "        if image_index == 0:\n",
        "            plt.title(\"Reconstruction\", fontsize=18, pad=10)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_reconstructions(autoencoder)\n"
      ],
      "metadata": {
        "id": "MakmR-3S0A5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Visualization Utility"
      ],
      "metadata": {
        "id": "GwGvhOit0Dxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_compressed(x_compressed, y, images, result='Result', class_names=None):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    cmap = plt.cm.tab10\n",
        "    Z = (x_compressed - x_compressed.min()) / (x_compressed.max() - x_compressed.min())\n",
        "    scatter = plt.scatter(Z[:, 0], Z[:, 1], c=y, s=10, cmap=cmap)\n",
        "\n",
        "    image_positions = np.array([[1., 1.]])\n",
        "    for index, position in enumerate(Z):\n",
        "        dist = ((position - image_positions) ** 2).sum(axis=1)\n",
        "        if dist.min() > 0.02:\n",
        "            image_positions = np.r_[image_positions, [position]]\n",
        "            imagebox = mpl.offsetbox.AnnotationBbox(\n",
        "                mpl.offsetbox.OffsetImage(images[index].reshape(28,28), cmap=\"binary\", zoom=0.6),\n",
        "                position,\n",
        "                bboxprops={\"edgecolor\": cmap(y[index]), \"lw\": 1}\n",
        "            )\n",
        "            plt.gca().add_artist(imagebox)\n",
        "\n",
        "    if class_names:\n",
        "        handles = [plt.Line2D([0], [0], marker='o', color='w', label=class_names[i],\n",
        "                              markerfacecolor=cmap(i), markersize=6) for i in np.unique(y)]\n",
        "        plt.legend(handles=handles, loc='best', fontsize=10)\n",
        "\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"{result}: 2D Latent Space\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "_tnHBcxb0PGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply PCA and t-SNE"
      ],
      "metadata": {
        "id": "AYMU7UoY0UC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=encoder_output_shape).fit(X_train)\n",
        "X_valid_pca = pca.transform(X_valid)\n",
        "X_valid_pca_tsne = TSNE(n_components=2, random_state=42).fit_transform(X_valid_pca)\n",
        "\n",
        "X_valid_ae = encoder.predict(X_valid)\n",
        "X_valid_ae_tsne = TSNE(n_components=2, random_state=42).fit_transform(X_valid_ae)\n"
      ],
      "metadata": {
        "id": "fUll2NKc0bJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering and Metrics"
      ],
      "metadata": {
        "id": "Yj5s2g-R0hnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans_ae = KMeans(n_clusters=10, random_state=42, n_init='auto').fit(X_valid_ae)\n",
        "kmeans_pca = KMeans(n_clusters=10, random_state=42, n_init='auto').fit(X_valid_pca)\n",
        "\n",
        "labels_ae = kmeans_ae.fit_predict(X_valid_aed)\n",
        "labels_pca = kmeans_pca.fit_predict(X_valid_pca)\n",
        "\n",
        "ari_ae = adjusted_rand_score(y_valid, kmeans_ae.labels_)\n",
        "ari_pca = adjusted_rand_score(y_valid, kmeans_pca.labels_)\n",
        "\n",
        "hom_ae = homogeneity_score(y_valid, kmeans_ae.labels_)\n",
        "hom_pca = homogeneity_score(y_valid, kmeans_pca.labels_)\n",
        "\n",
        "sil_ae = silhouette_score(X_valid_ae, kmeans_ae.labels_)\n",
        "sil_pca = silhouette_score(X_valid_pca, kmeans_pca.labels_)\n",
        "\n",
        "print(f\"ARI (Autoencoder): {ari_ae:.3f}\")\n",
        "print(f\"ARI (PCA): {ari_pca:.3f}\")\n",
        "print(f\"Homogeneity (Autoencoder): {hom_ae:.3f}\")\n",
        "print(f\"Homogeneity (PCA): {hom_pca:.3f}\")\n",
        "print(f\"Silhouette (Autoencoder): {sil_ae:.3f}\")\n",
        "print(f\"Silhouette (PCA): {sil_pca:.3f}\")\n"
      ],
      "metadata": {
        "id": "zv_bJJQN0mBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize t-SNE Embeddings"
      ],
      "metadata": {
        "id": "nWkJUiK00pRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_compressed(X_valid_pca_tsne, y_valid, X_valid, result='PCA t-SNE', class_names=class_names)\n",
        "visualize_compressed(X_valid_ae_tsne, y_valid, X_valid, result='Autoencoder t-SNE', class_names=class_names)\n",
        "\n",
        "visualize_compressed(X_valid_aed_tsne, labels_ae, X_valid, result='Autoencoder KMeans Clustering',class_names=cluster_labels)\n",
        "visualize_compressed(X_valid_pca_tsne, labels_pca, X_valid, result='PCA KMeans Clustering',class_names=cluster_labels)\n"
      ],
      "metadata": {
        "id": "a445mYw90wKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Observations\n",
        "\n",
        "- The **Autoencoder** achieves slightly better **Homogeneity** and **Silhouette** scores than PCA.\n",
        "- However, **PCA** is still competitive and often faster to compute.\n",
        "- Reconstruction quality is significantly better with the autoencoder due to its non-linear capacity.\n",
        "\n",
        "###  Theoretical Insight\n",
        "\n",
        "> If the autoencoder uses only **linear activations** and the cost function is **MSE**, it ends up performing **PCA** (as shown in Chapter 8 of Hands-On ML).\n",
        "\n",
        "Since our autoencoder uses non-linear activations, it can **learn more complex manifolds** and outperform PCA in certain settings, especially for reconstruction tasks.\n",
        "\n",
        "###  Final Thought\n",
        "\n",
        "Use **PCA** when you want speed and interpretability.\n",
        "\n",
        "Use **Autoencoders** when you want non-linear compression, better reconstructions, and can afford extra training time.\n"
      ],
      "metadata": {
        "id": "9O8AjU8-0ywC"
      }
    }
  ]
}
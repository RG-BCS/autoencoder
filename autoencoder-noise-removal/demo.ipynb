{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Autoencoder for Noise Removal on Fashion MNIST\n",
        "This notebook demonstrates how a convolutional autoencoder can be used to remove noise from the Fashion MNIST dataset. We add noise to the images, then train a denoising autoencoder to reconstruct the original images. We also evaluate the model's performance using PSNR (Peak Signal-to-Noise Ratio) and SSIM (Structural Similarity Index).\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "2aSnWhK6dTie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **1. Setup & Importing Libraries**\n",
        "First, we import all the necessary libraries for the project.\n",
        "\n"
      ],
      "metadata": {
        "id": "3GN4fU-pdX-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "7ifIiGrvdatr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load & Prepare the Fashion MNIST Dataset"
      ],
      "metadata": {
        "id": "V6vv6FBBddIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Split training set into train and validation sets\n",
        "X_train, X_valid, X_test = X_train[5000:] / 255.0, X_train[:5000] / 255.0, X_test / 255.0\n",
        "y_train, y_valid = y_train[5000:], y_train[:5000]\n",
        "\n",
        "# Reshape to add channel dimension for CNN input\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_valid = X_valid[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]\n"
      ],
      "metadata": {
        "id": "SQ9i1IZYdhjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Add Noise to the Images"
      ],
      "metadata": {
        "id": "Dn11-Y0FdmiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noise_factor = 0.2\n",
        "X_train_noisy = np.clip(X_train + noise_factor * np.random.rand(*X_train.shape), 0, 1)\n",
        "X_valid_noisy = np.clip(X_valid + noise_factor * np.random.rand(*X_valid.shape), 0, 1)\n",
        "X_test_noisy = np.clip(X_test + noise_factor * np.random.rand(*X_test.shape), 0, 1)\n"
      ],
      "metadata": {
        "id": "MMhWxHUbdpKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Visualize Noisy Images"
      ],
      "metadata": {
        "id": "2p3sxJ_adr5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_noise_images(X_clean, X_noisy, title):\n",
        "    plt.figure(figsize=(14, 3))\n",
        "    plt.suptitle(title, fontsize=16, y=1.05)\n",
        "    num_images = min(10, len(X_clean))  # Display up to 10 images\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(2, 10, i + 1)\n",
        "        plt.imshow(X_clean[i], cmap='binary')\n",
        "        plt.title('Original', fontsize=8)\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(2, 10, i + 11)\n",
        "        plt.imshow(X_noisy[i], cmap='binary')\n",
        "        plt.title('Noisy', fontsize=8)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_noise_images(X_train, X_train_noisy, \"Original and Noisy Training Images\")\n"
      ],
      "metadata": {
        "id": "XIQTTj8NdwT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Define the Denoising Autoencoder Model"
      ],
      "metadata": {
        "id": "Zpiye7YddzeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DenoiseAutoEncoder(keras.Model):\n",
        "    def __init__(self, input_shape, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder_ = keras.Sequential([\n",
        "            keras.layers.InputLayer(shape=input_shape),\n",
        "            keras.layers.Conv2D(16, 3, padding='same', strides=2, activation='relu'),\n",
        "            keras.layers.Conv2D(8, 3, padding='same', strides=2, activation='relu')\n",
        "        ])\n",
        "        self.decoder_ = keras.Sequential([\n",
        "            keras.layers.Conv2DTranspose(8, 3, padding='same', strides=2, activation='relu'),\n",
        "            keras.layers.Conv2DTranspose(16, 3, padding='same', strides=2, activation='relu'),\n",
        "            keras.layers.Conv2D(1, 3, padding='same', strides=1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "        latent_space = self.encoder_(x)\n",
        "        output_ = self.decoder_(latent_space)\n",
        "        return output_\n"
      ],
      "metadata": {
        "id": "cen3MeoMd31r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Train the Denoising Autoencoder"
      ],
      "metadata": {
        "id": "LTrmctfPd6lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "image_shape = X_train_noisy.shape[1:]\n",
        "model = DenoiseAutoEncoder(image_shape)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=keras.losses.MeanSquaredError(), optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_noisy, X_train, epochs=30, shuffle=True, validation_data=(X_valid_noisy, X_valid), verbose=1)\n",
        "\n",
        "# Plot training history\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eMvd7l6Kd-g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Reconstruct Images Before and After Training"
      ],
      "metadata": {
        "id": "spSbIwzheA-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_reconstruct_images(model, X_noisy, model_status='before'):\n",
        "    x = X_noisy[:10]\n",
        "    y = model(X_noisy[:10])\n",
        "    plt.figure(figsize=(14, 3))\n",
        "    plt.suptitle(f\"{model_status.capitalize()} Model Reconstructed Images\", fontsize=16, y=1.05)\n",
        "    for i in range(len(x)):\n",
        "        plt.subplot(2, 10, i + 1)\n",
        "        plt.imshow(x[i], cmap='binary')\n",
        "        plt.title('Noisy Input', fontsize=8)\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(2, 10, i + 11)\n",
        "        plt.imshow(y[i], cmap='binary')\n",
        "        plt.title('Reconstructed', fontsize=8)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Reconstruct before training\n",
        "model_reconstruct_images(model, X_train_noisy, model_status='before')\n",
        "\n",
        "# Reconstruct after training\n",
        "model_reconstruct_images(model, X_train_noisy, model_status='after')\n"
      ],
      "metadata": {
        "id": "PFYpc1IleEMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Apply Gaussian Blur to Test Set"
      ],
      "metadata": {
        "id": "kjwZuZ_UeHOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Gaussian blur to each image in the noisy test set\n",
        "X_test_blurred = np.array([gaussian_filter(img.squeeze(), sigma=1) for img in X_test_noisy])\n",
        "\n",
        "# Reshape back to (28, 28, 1)\n",
        "X_test_blurred = X_test_blurred[..., np.newaxis]\n",
        "\n",
        "# Visualize the blurred images\n",
        "plot_noise_images(X_test_noisy, X_test_blurred, \"Noisy Images and Gaussian Blurred Versions\")\n"
      ],
      "metadata": {
        "id": "tw8xJ43LeMNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Latent Space Visualization with t-SNE"
      ],
      "metadata": {
        "id": "Eo_3_vq8eO62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the latent space with t-SNE\n",
        "X_val_noise_pred = model.encoder_.predict(X_valid_noisy).reshape(X_valid.shape[0], -1)\n",
        "X_val_noise_tsne = TSNE(n_components=2, random_state=42, perplexity=30, learning_rate=200).fit_transform(X_val_noise_pred)\n",
        "\n",
        "# Visualize the compressed latent space\n",
        "def visualize_compressed(x_compressed, y, images, result='PCA_Results', class_names=None):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    cmap = plt.cm.tab10\n",
        "    Z = (x_compressed - x_compressed.min()) / (x_compressed.max() - x_compressed.min())  # normalize\n",
        "    scatter = plt.scatter(Z[:, 0], Z[:, 1], c=y, s=10, cmap=cmap)\n",
        "    image_positions = np.array([[1., 1.]])\n",
        "    for index, position in enumerate(Z):\n",
        "        dist = ((position - image_positions) ** 2).sum(axis=1)\n",
        "        if dist.min() > 0.02:  # avoid overlapping image previews\n",
        "            image_positions = np.r_[image_positions, [position]]\n",
        "            imagebox = mpl.offsetbox.AnnotationBbox(\n",
        "                mpl.offsetbox.OffsetImage(images[index].reshape(28, 28), cmap=\"binary\", zoom=0.6),\n",
        "                position,\n",
        "                bboxprops={\"edgecolor\": cmap(y[index]), \"lw\": 1}\n",
        "            )\n",
        "            plt.gca().add_artist(imagebox)\n",
        "\n",
        "    if class_names:\n",
        "        handles = [plt.Line2D([0], [0], marker='o', color='w', label=class_names[i],\n",
        "                              markerfacecolor=cmap(i), markersize=6)\n",
        "                   for i in np.unique(y)]\n",
        "        plt.legend(handles=handles, loc='best', fontsize=10)\n",
        "\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"{result}: 2D Latent Space with Class Labels and Sample Images\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_compressed(X_val_noise_tsne, y_valid, X_valid, result='Autoencoder_Results', class_names=['Cluster ' + str(i) for i in range(10)])\n"
      ],
      "metadata": {
        "id": "FJ4ydbNgeSml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Evaluation: PSNR and SSIM"
      ],
      "metadata": {
        "id": "dB6MPFxoeXti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict denoised test images\n",
        "denoised = model.predict(X_test_noisy, verbose=0)\n",
        "\n",
        "# Evaluate PSNR\n",
        "avg_psnr = np.mean([psnr(X_test[i].squeeze(), denoised[i].squeeze(), data_range=1.0)\n",
        "                    for i in range(len(X_test))])\n",
        "print(\"Average PSNR > 30 (preferable and indicates excellent denoising):\", avg_psnr)\n",
        "\n",
        "# Evaluate SSIM\n",
        "avg_ssim = np.mean([ssim(X_test[i].squeeze(), denoised[i].squeeze(), data_range=1.0)\n",
        "                    for i in range(len(X_test))])\n",
        "print(\"Average SSIM ~ 1 (Closer to 1.0 is ideal, reflects structural similarity):\", avg_ssim)\n"
      ],
      "metadata": {
        "id": "DZMx4EeYdCKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "Our denoising autoencoder was able to significantly clean noisy images from the Fashion MNIST dataset.\n",
        "\n",
        "- **Average PSNR**: ~25.7 — quite good but leaves room for optimization (ideal is >30).\n",
        "- **Average SSIM**: ~0.90 — indicating good structural preservation.\n",
        "\n",
        "### Future Improvements:\n",
        "- Use deeper architectures or skip connections (e.g., U-Net).\n",
        "- Try different types of noise (salt & pepper, speckle).\n",
        "- Use adversarial training for sharper outputs (e.g., Denoising GAN).\n",
        "\n",
        "This setup demonstrates a practical application of unsupervised learning to clean noisy data and recover structured input — a valuable tool in image processing pipelines.\n"
      ],
      "metadata": {
        "id": "rmNL0TeJc8JB"
      }
    }
  ]
}